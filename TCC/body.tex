% Assume-se que \textual já foi feito

\newcommand{\multicore}{\textit{multicore}\xspace}
\newcommand{\chip}{\textit{chip}\xspace}
\newcommand{\chips}{\textit{chips}\xspace}
\newcommand{\singlecore}{\textit{single core}\xspace}
\newcommand{\tradeoff}{\textit{trade-off}\xspace}
\newcommand{\exascale}{\textit{Exascale}\xspace}
\newcommand{\greencomputing}{\textit{Green Computing}\xspace}  
\newcommand{\ranking}{\textit{ranking}\xspace}
\newcommand{\benchs}{\textit{benchmarks}\xspace}
\newcommand{\etal}{\textit{et al}.\xspace}
\newcommand{\thread}{\textit{thread}\xspace}
\newcommand{\threads}{\textit{threads}\xspace}
\newcommand{\cache}{\textit{cache}\xspace}
\newcommand{\caches}{\textit{caches}\xspace}
\newcommand{\byte}{\textit{byte}\xspace}
\newcommand{\bytes}{\textit{bytes}\xspace}
\newcommand{\transistor}{\textit{transistor}\xspace}
\newcommand{\transistors}{\textit{transistors}\xspace}
\newcommand{\hardware}{\textit{hardware}\xspace}
\newcommand{\cluster}{\textit{cluster}\xspace}
\newcommand{\clusters}{\textit{clusters}\xspace}
\newcommand{\kernel}{\textit{kernel}\xspace}
\newcommand{\kernels}{\textit{kernels}\xspace}
\newcommand{\offset}{\textit{offset}\xspace}
\newcommand{\offsets}{\textit{offsets}\xspace}
\newcommand{\master}{\textit{master}\xspace}
\newcommand{\masters}{\textit{masters}\xspace}
\newcommand{\slave}{\textit{slave}\xspace}
\newcommand{\slaves}{\textit{slaves}\xspace}

\chapter{Introdução}
\label{ch:introdução}

Os avanços na indústria de semicondutores, juntamente com a área de arquitetura de computadores, são notados desde a década de 1980, permitindo um crescimento anual em desempenho de processadores \singlecore de 40\% a 50\% \cite{Larus2008}. Porém, a necessidade de uma nova classe de processadores mostrou-se eminente ao se atingir um ponto onde o \tradeoff entre gasto energético e aumento em desempenho era desproporcional, havendo muita dissipação de calor para pouco crescimento em performance. Essa barreira de potência foi então a responsável pelo interesse da indústria de semicondutores na classe de processadores \multicore. 

Arquiteturas paralelas do tipo \multicore atualmente seguem para uma barreira similar a encontrada pelas \singlecore, visto que, seu principal método de evolução, o aumento no número de núcleos em um mesmo \chip, possui uma limitação, sendo esta o tamanho mínimo que um \transistor pode alcançar, resultando no fim da possibilidade de alocação de mais núcleos em um mesmo espaço, tendo como única opção o aumento do tamanho do \chip. Além disso, soluções que utilizam esse tipo de arquitetura, por exemplo, supercomputadores, estão encontrando o mesmo problema de escalabilidade entre dissipação de calor e ganho em desempenho que os \singlecore encontraram no passado. A Figura \ref{fig:eficienciaxcorestop500} exemplifica esse problema, pois, utilizando a medida de performance \textit{\Flops}, ou seja, a quantidade de operações de ponto flutuante que um computador realiza por segundo, compara seu crescimento com o aumento no número de núcleos dos supercomputadores com maior poder de computação do mundo ao passar dos anos, segundo o \ranking TOP500\footnote{Os dados do \ranking TOP500 estão disponíveis no site TOP500: https://www.top500.org/}, mostrando ao mesmo tempo a tendência em aumentar o número de núcleos e a difícil tarefa de encontrar escalabilidade entre esse aumento e o ganho em eficiência.

Com o interesse atual da comunidade científica em atingir o \exascale e, ao mesmo tempo, em computação voltada para a eficiência energética, pode-se então afirmar que as arquiteturas do tipo \multicore não são mais uma solução viável para os supercomputadores. O alerta do Departamento de Defesa do Governo dos Estados Unidos (DARPA), uma das organizações mais importante do país, serve também como base para essa afirmação, o qual mostrou em um relatório \cite{darpa:exascale} que, para ser viável, um supercomputador da era  \exascale deve atingir uma eficiência energética de 50 G\Flops/W, enquanto que, atualmente, o supercomputador com o maior poder de processamento do mundo atinge 14.719 G\Flops/W e o de melhor eficiência energética atinge 16.876 G\Flops/W. A Figura \ref{fig:eficienciaxyearstop500} mostra o crescimento na eficiência energética dos supercomputadores mais poderosos do mundo desde 2005\footnote{Foi escolhido este ano como início pois nos anos anteriores a eficiência energética ainda era menor que 0.1 GFlops/W.}, segundo o \ranking TOP500.

\begin{figure}[tb]
  \centering
  \caption{Comparação da evolução da eficiência energética em relação ao número de núcleos do supercomputador número 1 do mundo ao passar dos anos segundo o \ranking TOP500.}
  \label{fig:eficienciaxcorestop500}
  \includegraphics[width=1\linewidth, keepaspectratio]{Figure_Efficiency_X_Cores_Top500.pdf}
  \fonte{Gráfico desenvolvido pelo autor.}
\end{figure}

\begin{figure}[tb]
  \centering
  \caption{Evolução da eficiência energética do supercomputador número 1 do mundo segundo o \ranking TOP500.}
  \label{fig:eficienciaxyearstop500}
  \includegraphics[width=1\linewidth, keepaspectratio]{Figure_Efficiency_X_Years_Top500.pdf}
  \fonte{Gráfico desenvolvido pelo autor.}
\end{figure}

Buscando novos tipos de arquiteturas paralelas que apresentem as características faltantes no problema de balanceamento apresentado acima, pesquisadores da área de \textit{\HPC} realizaram diversos estudos voltados para essa questão, aplicando conceitos de \greencomputing \cite{greencomputingacm} no decorrer do desenvolvimento de suas soluções. Dentre estas soluções, temos o surgimento da classe de processadores \manycore de baixa potência, como o \mppa \cite{mppa2562013}, objeto de estudo deste trabalho, o Adapteva Epiphany \cite{olofsson2014}, e o SW26010, utilizado no atual terceiro supercomputador mais poderoso do mundo, o \textit{Sunway TaihuLight} \cite{fu2016sunway}. Vale citar que o SW26010 desbancou em 2016 o supercomputador que assumia, desde 2013, a primeira posição do \ranking TOP500, obtendo duas vezes mais desempenho que esse e reduzindo em três vezes o consumo energético, explicando também o ganho elevado em eficiência em ambas as Figuras \ref{fig:eficienciaxcorestop500} e \ref{fig:eficienciaxyearstop500} no mês de junho de 2016.

Para avaliar o desempenho e consumo energético do \mppa, \textit{Souza} \etal \cite{Castro-Souza-CCPE:2016} propuseram o desenvolvimento do \bench \capb, o qual, em sua primeira versão, utilizava uma \textit{\API} de comunicação síncrona entre processos denominada \textit{\IPC} \cite{mppa2562013}. Essa \API possui algumas deficiências, como o baixo nível de abstração, requerendo conhecimento prévio da arquitetura alvo para implementações paralelas eficientes, e a realização de sincronizações implícitas muitas vezes não necessárias nas operações de envio e recebimento de dados, o que leva a queda de desempenho da aplicação. Recentemente, uma nova \API de comunicação denominada \textit{\ASYNC} foi desenvolvida pela empresa fabricante do  \mppa. Esta \API fornece um maior nível de abstração e a possibilidade de realização de comunicações assíncronas, aumentando, assim, o potencial de desempenho das aplicações. Portanto, mostra-se necessária a realização de um estudo para verificar os reais benefícios desta nova \API.

\section{Objetivos}
\label{sec:objetivos}

Com base no que foi exposto, são apresentados abaixo o objetivo geral e os objetivos específicos deste trabalho.

\subsection{Objetivo Geral}
\label{sec:objetivogeral}

Este trabalho tem por objetivo geral a adaptação da implementação das aplicações do \capb para a \API \ASYNC, assim como um estudo do desempenho das aplicações em comparação com a implementação original com a \API \IPC no \mppa.

\subsection{Objetivos Específicos}
\label{sec:objetivosespecifico}

\begin{itemize}
\item Estudar as \APIs de comunicação \ASYNC e \IPC no \mppa;
\item Avaliar os custos e benefícios do \mppa em relação ao desempenho e gasto energético, assim como sua utilidade para a Computação Sustentável (\greencomputing);
\item Comparar as \APIs \ASYNC e \IPC a fim de prover métricas precisas para a escolha da melhor \API de comunicação.
\end{itemize}

\section{Contribuições do trabalho}

Este trabalho é continuação de um projeto de iniciação científica desenvolvido autor, o qual resultou em um artigo publicado na Escola Regional de Alto Desempenho da Região Sul no ano de 2019:

\begin{itemize}
  \item ORDINE, D. G. V.; PODESTA JUNIOR, E. ; PENNA, P. H. ; CASTRO, M. \textbf{Otimização de Aplicações do CAP Bench para o Processador \mppa.} In: Escola Regional de Alto Desempenho da Região Sul (ERAD/RS), 2019, Três de Maio. Anais da Escola Regional de Alto Desempenho da Região Sul (ERAD/RS). Porto Alegre: Sociedade Brasileira de Computação (SBC), 2019.
\end{itemize}

\section{Organização do trabalho}

Este trabalho está dividido da seguinte forma. O Capítulo \ref{ch:fundamentacaoteorica} mostra os conceitos teóricos que foram utilizados para a produção deste trabalho. O Capítulo \ref{ch:trabcorrelatos} apresenta alguns trabalhos relacionados a este. O Capítulo \ref{ch:desenvolvimento} apresenta a proposta deste projeto. O Capítulo \ref{ch:resultados} apresenta os resultados obtidos. Por fim, o Capítulo \ref{ch:conclusao} conclui este trabalho.

\chapter{Fundamentação Teórica}
\label{ch:fundamentacaoteorica}

Neste capítulo são apresentados inicialmente conceitos fundamentais sobre arquiteturas paralelas (Seção \ref{sec:arquiteturasparalelas}), e, mais especificamente, sobre o \mppa (Seção \ref{sec:mppa256}). Então, são discutidas algumas tecnologias de programação paralela bastante difundidas na literatura, além das tecnologias existentes para o processador \mppa (Seção \ref{sec:bibliotecasdevparalelo}).

\section{Arquiteturas Paralelas}
\label{sec:arquiteturasparalelas}

Segundo \textit{Tanenbaum} \etal, existem dois tipos de sistemas com múltiplos processadores: os multiprocessadores e os multicomputadores \cite{TanenbaumMordenOS}. Esta seção apresenta as principais características de cada uma dessas abordagens.

\subsection{Multiprocessadores}
\label{sec:multiprocessadores}

A principal característica de uma arquitetura multiprocessador é o acesso compartilhado ao barramento de memória do sistema, a \textit{\RAM}, por diversas \textit{\CPUs}. Cada programa em execução nesta arquitetura possui seu próprio espaço de endereçamento na \RAM, o qual é compartilhado por todas as \threads que o compõe. Toda a comunicação entre \threads é feita de maneira implícita, através de operações de escrita e leitura. Devido ao compartilhamento de memória, há a possibilidade de ocorrer problemas de concorrência quando duas ou mais \threads de um mesmo programa escrevem um valor em uma mesma posição de memória simultaneamente, ocasionando assim problemas de condição de corrida.

Multiprocessadores são também classificados em dois tipos, de acordo com a latência de acesso à memória. Nos multiprocessadores com acesso uniforme a memória, \textit{\UMA}, a latência de acesso à memória é constante, independentemente do processador e do endereço de memória que está sendo acessado. Por outro lado, nos multiprocessadores com acesso não uniforme a memória, \textit{\NUMA}, a latência é variável e depende da distância entre o processador e o bloco de memória que está sendo acessado.

A arquitetura mais simples de um multiprocessador \UMA, exemplificada na Figura \ref{fig:umasimples}, envolve um único barramento conectando duas ou mais \CPUs a um módulo de memória, permitindo que todas as \CPUs realizem operações de leitura e escrita neste módulo. Quando uma \CPU necessita ler alguma palavra da memória, primeiramente ela verifica se o barramento está ocupado. Caso não, informa à memória, através do barramento, qual endereço deseja obter o valor, aguardando o recebimento deste pelo mesmo barramento. Caso esteja, a \CPU aguarda a liberação do barramento. Para uma pequena quantidade de \CPUs, o tempo de espera médio para o acesso ao barramento tende a ser pequeno e tolerável. Porém, quando elevam-se em algumas dezenas o número de \CPUs observa-se o principal problema deste exemplo de arquitetura \UMA: a ociosidade, por muito tempo, de grande parte das \CPUs, enquanto aguardam pelo acesso ao barramento.

\begin{figure}[tb]
  \centering
  \caption{Diferentes esquemas possiveis de um multiprocessador UMA baseado em barramento.}
  \subcaptionminipage[fig:umasimples]%
    {.4\linewidth}%
    {Sem \textit{cache}}%
    {\includegraphics[width=.9\linewidth]{umasimples.pdf}}%
  \hfill% 
  \subcaptionminipage[fig:umacomcache]%
    {.4\linewidth}%
    {Com \textit{cache}}%
    {\includegraphics[width=.9\linewidth]{umacomcache.pdf}}%
  \hfill% 
  \subcaptionminipage[fig:umacomcacheememprivada]%
    {.4\linewidth}%
    {Com \textit{cache} e memórias privadas}%
    {\includegraphics[width=.9\linewidth]{umacomcacheememprivada.pdf}}%
  \hfill% 
  \fonte{Imagens desenvolvidas pelo autor, adaptadas de \textit{Tanenbaum} \etal \cite{TanenbaumMordenOS}.}
\end{figure}

Adicionar \caches às \CPUs, como na Figura \ref{fig:umacomcache}, é uma solução para reduzir o gargalo imposto sobre o barramento, já que agora valores podem ser lidos diretamente da \cache local, a qual está muito mais próxima da \CPU e possui tempo de acesso muito menor. Outra possibilidade é adicionar, além das \caches, memórias privadas locais,  como na Figura \ref{fig:umacomcacheememprivada}. Compiladores podem colocar nessas memórias todos os dados que são somente de leitura, por exemplo, constantes e o código do programa, utilizando assim esta segunda configuração de forma otimizada. Ambas configurações removem grande parte do tráfego no barramento.

A adição de \caches impõe uso de protocolos de coerência para que não haja inconsistência entre os valores de um mesmo endereço de memória nas diferentes \caches. Primeiramente, para otimizar as operações de leitura, quando uma palavra é referenciada, todo o bloco que contém essa palavra, geralmente de 32 ou 64 \bytes, é colocado na \cache. Já para garantir a coerência, cada bloco é marcado como sendo somente de leitura, podendo assim estar presente em outras \caches, ou de leitura e escrita, não devendo estar presente em nenhuma outra \cache neste caso. Quando uma \CPU tenta alterar um valor que está presente em outras \caches além de sua própria, o \hardware do barramento informa essa operação às outras \caches, as quais tratam esse contexto de duas formas. Caso o valor da \cache seja o mesmo em memória, podem simplesmente descartá-lo, buscando o novo valor na memória se necessário. Caso outra \cache tenha um valor diferente daquele em memória, é necessário ou salvá-lo na memória ou transferi-lo diretamente para a \cache que solicitou a operação de escrita.

Quando necessita-se de um número de processadores na ordem das centenas, a arquitetura \UMA acaba sendo inviável. Assim, introduz-se a arquitetura \NUMA, trazendo com ela a ideia de diferentes tempos de acesso para diferentes posições de memória. Multiprocessadores \NUMA provém essa escalabilidade implementando um espaço de endereçamento único para todas as \CPUs através de uma rede de interconexão, como na Figura \ref{fig:multiprocessadornuma}, o que causa a diferença nos tempos de acesso, os quais serão totalmente dependentes do local da memória que se deseja acessar um valor relativo ao local da \CPU que requisitou este acesso. Logo, outra propriedade desta arquitetura é o acesso mais rápido à memória local de um ou um conjunto de \CPUs, em comparação com o acesso à memória remota. Vale salientar que programas desenvolvidos para multiprocessadores \UMA conseguem ser executados em arquiteturas \NUMA, devido a ambas possuírem um espaço de endereçamento único. Porém, estes programas irão obter performance inferior, já que não foram otimizados para considerar as diferenças de tempo entre acesso à memória local e remota.

\begin{figure}[tb]
  \centering
  \caption{Esquema genérico de um multiprocessador NUMA.}
  \label{fig:multiprocessadornuma}
  \includegraphics[width=.9\linewidth, keepaspectratio]{numa.pdf}
  \fonte{Imagem desenvolvida pelo autor, adaptada de \textit{Tanenbaum} \etal \cite{TanenbaumMordenOS}.}
\end{figure}

A medida que o tamanho de um \transistor diminui, o número de \transistors em um \chip tende a aumentar. Diversas soluções exploram o que fazer com este número crescente de \transistors, por exemplo, adicionar \caches poderosas de muitos \textit{mega}\bytes ou colocar duas ou mais \CPUs, também chamadas de núcleos (em inglês \textit{cores}), neste mesmo \chip. Em certo ponto, o aumento no tamanho da \cache traz pouquíssimo ganho em porcentagem de \textit{hit} (quantidade de vezes que é possível buscar um dado diretamente na \cache), mostrando assim que o investimento no paralelismo trazido pelos múltiplos núcleos como recurso para ganho em desempenho é uma opção a se considerar. Assim, \chips \multicore são uma mescla de múltiplas \CPUs com múltiplos níveis de \cache inseridos em um espaço muito menor que um multiprocessador, sendo por isso também chamados de \textit{\CMPs}.

Apesar de serem parecidos, existem algumas diferenças entre os \CMPs e os multiprocessadores. Primeiramente, em muitos \CMPs ocorre o compartilhamento da \cache nível 2 ou 3 entre suas \CPUs, o que não acontece nos multiprocessadores, que possuem \caches totalmente privadas em todos os níveis. Além disso, a probabilidade de que falhas em componentes compartilhados levem a impossibilidades em múltiplas \CPUs ao mesmo tempo é muito maior nos \CMPs, devido a proximidade de conexão das \CPUs. Por fim, existem \chips \multicore em que todos os núcleos são feitos para atender a uma ampla gama de contextos, enquanto que em outros, além das \CPUs principais, existem também núcleos específicos para alguns problemas, como decodificação de áudio e vídeo ou interfaces de rede. 

Apesar de não haver uma barreira de distinção entre um \chip \manycore ou \multicore, pode-se chama-lo de \manycore quando a perda de um núcleo tem um pequeno impacto na performance total do \chip. Um problema com arquiteturas \manycore é a escalabilidade entre manter as \caches de todas as \CPUs coerentes e ainda assim elevar o desempenho ao elevar o número de núcleos. Cientistas da área de \HPC temem que essas duas variaveis não escalem proporcionalmente, tornando o custo de gerenciar essas \caches tão alto que a adição de um novo núcleo de pouco ajudara no aumento em performance. Este problema é também conhecido como a barreira de coerência  (\textit{coherency wall}) \cite{TanenbaumMordenOS}.

Para o futuro dos \manycores, espera-se processadores que invistam mais  na comunicação entre \CPUs através da troca de mensagens extremamente rápidas via \hardware e através de uma memória compartilhada, deixando de lado parte da coerência de \cache. Uma \GPU é um dos exemplos mais comuns de um processador \manycore, possuindo milhares de pequenos núcleos especializados na rápida execução de cálculos e sem uma lógica complexa de \cache, ou seja, priorizam o processamento. Desta maneira, \GPUs são excepcionais para a execução paralela de pequenas tarefas, como a renderização de \textit{frames} para jogos. Programar para uma \GPU é uma tarefa difícil e muitas vezes algumas linguagens de programação especiais são utilizadas, como a OpenGL ou a CUDA, da NVIDIA. Essa dificuldade se dá, principalmente, pelo fato dos núcleos de uma \GPU executarem exatamente a mesma instrução em diferentes fatias de um dado, ou seja, pelo fato da \GPU ser uma máquina \textit{\SIMD}.

\subsection{Multicomputadores}
\label{sec:multicomputadores}

Multicomputadores surgiram na dificuldade de aumentar o poder de processamento de um multiprocessador quando se atinge grandes escalas em relação ao número de núcleos. Ao contrário dos multiprocessadores, multicomputadores não compartilham memória, sendo relativamente fáceis de se construir, tendo como componente principal um computador com uma placa de rede de alta performance, sem mouse, teclado e monitor. Neste sistema, também chamado de \textit{Cluster Computers} ou \textit{Cluster Of Workstations} (COWs), é necessário um \textit{design} inteligente da rede que irá conectar os computadores para que se possa obter um alto desempenho.

Um nó de um multicomputador consiste então em um computador, com uma \CPU, memória, placa de rede e um HD. Diversas são as topologias possíveis para a rede que conecta os nós, como mostrado na Figura \ref{fig:topologiamulticomputadores}. Sistemas pequenos utilizam-se de apenas um \textit{switch} para conectar os nós entre si, os quais são então organizados em forma de estrela, como na Figura \ref{fig:topologiamulticomputadores}(a). Também é possível organizar os nós em forma de anel, onde cada nó se conecta aos nós da sua esquerda e direita, como na Figura \ref{fig:topologiamulticomputadores}(b), eliminando a necessidade de um \textit{switch}. Porém, o problema dessas arquiteturas é a escalabilidade, a qual dificulta o ganho em desempenho a medida que se aumenta o número de nós devido ao tempo de viagem dos dados entre nós.

\begin{figure}[tb]
  \centering
  \caption{Tipos de topologias de rede de multicomputadores.}
  \label{fig:topologiamulticomputadores}
  \includegraphics[width=.9\linewidth, keepaspectratio]{topologia.pdf}
  \fonte{\cite{TanenbaumMordenOS}.}
\end{figure}

Topologias mais complexas, como a malha (\textit{grid} ou \textit{mesh}), mostrada na Figura \ref{fig:topologiamulticomputadores}(c), ou a \textit{double torus}, mostrada na Figura \ref{fig:topologiamulticomputadores}(d), são mais escaláveis do que as apresentadas anteriormente. Nessas topologias, os nós são conectados em \textit{switches} e estes são conectados entre si, formando um \textit{layout} de malha no sistema. Dentre as duas citadas, a \textit{double torus} é mais escalável devido a conexão entre nós nas arestas da rede, trazendo assim conexões extras ao sistema, o que aumenta a tolerância a faltas e o desempenho, já que o caminho entre estes nós se torna menor. Este tipo de rede possui uma propriedade chamada de diâmetro, que é o caminho mais longo entre dois nós. Para topologias bidimensionais como a malha, o diâmetro aumenta proporcionalmente a raiz quadrada do número de nós. \textit{Layouts} \textit{n} dimensionais, como mostrado na Figura \ref{fig:topologiamulticomputadores}(e) (tridimensional) e na Figura \ref{fig:topologiamulticomputadores}(f) (quadrimensional), são ainda mais escaláveis, já que o diâmetro diminui à medida que se aumenta o número de dimensões da rede, tendo como única desvantagem o custo elevado, devido ao grande número de ligações presentes entre nós e \textit{switches}.

A comunicação entre processos rodando em diferentes \CPUs, num multicomputador, se dá através da troca de mensagens entre estes. Basicamente, o \SO presente no multicomputador é o responsável por realizar essa troca, através de funções acessíveis somente a ele. Porém, bibliotecas podem fornecer abstrações a essas funções, tornando a troca de mensagens também disponível para os processos usuário e as simplificando, visto que abstraem toda uma lista de invocações de funções em uma única função. Essa troca de mensagens pode ser reduzida a duas funções, chamadas de \textit{send} e \textit{receive}. A função \textit{send} é responsável por enviar uma mensagem de uma \CPU para outra, passando parâmetros como o destino da mensagem e o endereço onde aquela mensagem se encontra. Já a função \textit{receive} é responsável por receber a mensagem, tendo como parâmetros, por exemplo, o endereço de onde a mensagem será lida e o endereço onde será armazenada. Por fim, essas funções podem ser síncronas, bloqueando o processo que envia ou recebe a mensagem até que a operação seja concluída, ou assíncronas, não bloqueando o processo que realizou tal operação.

\section{\mppa}
\label{sec:mppa256}

\begin{figure}[tb]
  \centering
  \caption{Visão arquitetural simplificada do \mppa.}
  \label{fig:mppa256overview}
  \includegraphics[width=.7\linewidth, keepaspectratio]{mppa-overview.pdf}
  \fonte{\cite{Penna2018OS}.}
\end{figure}

Desenvolvido pela empresa francesa Kalray, o \mppa é um processador de baixa potência que reflete o estado da arte dos \manycores. Uma visão geral do processador é mostrada na Figura \ref{fig:mppa256overview}. O \mppa possui 16 \CCs e 4 \clusters de \IO. Cada \CC possui: \textbf{(i)} 16 núcleos para executar \textit{threads} de usuário em modo ininterrupto e não preemptivo, os quais atuam com frequência de 400 MHz; \textbf{(ii)} um gerenciador de recursos responsável por executar
o sistema operacional e gerenciar comunicações; \textbf{(iii)} uma memória compartilhada de 2MB, possibilitando alta largura de banda e taxa de transferência entre núcleos de um mesmo \cluster; e \textbf{(iv)} dois controladores de \textit{\NoC}, um para dados e outro para controle. Cada núcleo possui duas memórias \cache, uma para dados e outra para instruções. As \caches são associativas \textit{2-way} privadas e possuem 32kB \cite{Podesta2018Stencil}.

Por outro lado, \clusters de \IO realizam comunicações com dispositivos externos, onde dois destes apresentam acesso às memórias externas \textit{Low-Power Double Data Rate 3 (LPDDR3)} de 2GB. É importante salientar que um \CC não pode acessar diretamente os dados da memória de outros \clusters. Logo, o processador apresenta um modelo de memória distribuído \cite{Castro-Souza-CCPE:2016, Podesta2018Stencil}, se assemelhando, neste sentido, a um multicomputador.

\section{Desenvolvimento de Aplicações Paralelas}
\label{sec:bibliotecasdevparalelo}

Durante o domínio de processadores \singlecore no mercado, o aumento de desempenho de aplicações era fortemente influenciado pelo aumento da frequência de \textit{clock} dos processadores. Isso removia parte da responsabilidade do desenvolvedor em implementar melhorias na aplicação, já que bastava o \textit{upgrade} no \textit{hardware} para obter essas melhorias. Nestes processadores, instruções são executadas de forma sequencial em um único núcleo. Já em processadores \multicore e \manycore, existem múltiplos núcleos executando diferentes instruções, possivelmente, de diferentes programas. Essa divisão de tarefas pode levar a diversos novos problemas, como \textit{deadlock} ou condições de corrida, como dito anteriormente.

Diversas \APIs voltadas a programação paralela foram criadas para simplificar tanto a solução desses problemas como o desenvolvimento de aplicações que exploram o paralelismo de maneira eficaz. A seguir serão apresentadas duas das mais conhecidas \APIs para multiplataformas, a \textit{\OpenMP} e o \textit{\MPI}, assim como duas \APIs específicas para o \mppa, a \ASYNC e a \IPC.

\subsection{Bibliotecas multiplataforma}
\label{sec:bibliotecasmultiplataforma}

\subsubsection{Open Multi-Processing}
\label{sec:openmp}

A \OpenMP é uma das bibliotecas mais utilizadas para implementação de aplicações paralelas nas linguagens C, C++ e Fortran. Sua fama vem, principalmente, da abstração que a \API fornece, sendo possível ser utilizada em inúmeras plataformas. Por ser uma \API voltada ao \textit{multithreading}, utiliza-se do compartilhamento de memória entre as \threads de um mesmo programa para criar beneficios ao desenvolvedor, como variáveis de ambiente.

Esta biblioteca é centrada no modelo \textit{fork-join} (Figura \ref{fig:forkjoin}), onde, em determinados momentos do fluxo de execução de uma aplicação, temos a \thread principal instanciando outras \threads através de diretivas de compilação fornecidas pela própria \API, as quais serão executadas de forma independente, paralelamente ou concorrentemente entre si. A \thread principal também realiza uma sincronização com as \threads criadas através de uma barreira implícita, aguardando o término de todas as \threads para continuar com a execução. A criação de novas \threads se dá ao atingir uma região paralela, definida por algumas diretivas de compilação, como \texttt{\#pragma omp parallel for}, que paraleliza a execução de um \textit{loop} entre múltiplas \threads. O código \ref{lst:parallelloop} produz, de forma paralela, um \textit{array} com 10 posições, onde cada posição armazena um inteiro igual ao índice daquela posição.


\begin{figure}[tb]
  \centering
  \caption{Esquema do modelo \textit{fork-join}.}
  \label{fig:forkjoin}
  \includegraphics[width=.3\linewidth, keepaspectratio]{forkjoin.pdf}
  \fonte{\cite{forkjoinarticle}.}
\end{figure}

\begin{listing}[tb]
\caption{Execução de um \textit{loop} de forma paralela.}
\label{lst:parallelloop}
\begin{minted}[highlightlines={4}]{c}
static void createArray() {
  int array[max], index;
  int index_max = 10;
  #pragma omp parallel for
  for (index = 0; i < index_max; index++)
    array[index] = index;
}
\end{minted}
\fonte{o autor.}
\end{listing}

As diretivas \texttt{private, default e reduction} permitem, na sequência, definir quais variáveis terão escopo privado, qual será o escopo padrão das variáveis, e qual variável será feito uma redução sobre e qual será o tipo de redução (reduções são operações primitivas seguras sobre uma variável compartilhada entre múltiplas \threads). O Código \ref{lst:reductionloop} é parte de uma das aplicações do \capb, a \textit{Friendly Numbers}, e utiliza essas três diretivas para realizar uma contagem paralela, a qual será armazenada na variável \texttt{partial\_friendly\_sum}. Como é possível observar, com a adição de uma única linha paraleliza-se a execução de uma computação, sendo esta a maior vantagem da \OpenMP.

\begin{listing}[tb]
\caption{Leitura e armazenamento seguro em variável compartilhada entre \threads.}
\label{lst:reductionloop}
\begin{minted}[highlightlines={6}]{c}
static int partial_friendly_sum = 0;
...
static void countFriends() {
  int i; /* Loop indexes. */

  #pragma omp parallel for private(i) default(shared) reduction(+: partial_friendly_sum)
  for (i = offset; i < offset + tasksize; i++) {
    for (int j = 0; j < i; j++) {
      if ((allTasks[i].num == allTasks[j].num) && (allTasks[i].den == allTasks[j].den))
        partial_friendly_sum++;
    }
  }
}
\end{minted}
\fonte{o autor.}
\end{listing}

Também pode-se definir qual será o nível de trabalho de cada \thread com a diretiva \texttt{schedule}. Através desta diretiva, definem-se três tipos de escalonamentos para as \threads: \texttt{static}, \texttt{dynamic} e \texttt{guided}. Com o \texttt{static}, todas as \threads irão receber a mesma quantidade de trabalho, sendo este o escalonamento padrão. Já a diretiva \texttt{dynamic} é utilizada quando as iterações podem ter uma grande diferença no seu tempo de execução, realizando uma atribuição dinâmica de tarefas, onde cada \thread recebe uma nova tarefa ao terminar a iteração atual. Por fim, \texttt{guided} é similar ao \texttt{dynamic}, porém, a \thread começa recebendo um grande número de iterações, mas a medida que a execução avança, o número de iterações atribuídas a cada \thread é reduzido para melhorar o balanceamento de carga.

\subsubsection{Message Passing Interface}
\label{sec:mpi}

\begin{listing}[tb]
\caption{Exemplo de uma aplicação usando a MPI.}
\label{lst:programmpi}
\begin{minted}[highlightlines={10,14,17}]{c}
int main(int argc, char **argv) {
  int rank, size;

  char mensagem_bcast[25] = "Transmitindo um broadcast";
  char mensagem_bcast_recebido[18];

  MPI_Init(argc, argv);
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  MPI_Bcast(&mensagem_bcast, 25, MPI_CHAR, 0, MPI_COMM_WORLD);

  if (rank > 0) {
    mensagem_bcast_recebido[18] = "Broadcast recebido";
    MPI_Send (&mensagem_bcast_recebido, 18, MPI_CHAR, 0, 0, MPI_COMM_WORLD);
  } else if (rank == 0) {
    for (int i = 1; i < size; i++)
      MPI_Recv(&mensagem_bcast_recebido, 18, MPI_CHAR, i, 
        MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
  }

  MPI_Finalize();
  return 0;
}
\end{minted}
\fonte{o autor.}
\end{listing}

Diferentemente da \OpenMP, o \MPI é baseada no modelo \textit{\SPMD}, onde um mesmo programa é executado por diferentes processos, cada qual com o seu próprio espaço de endereçamento. Assim, o \MPI é usada em supercomputadores para abstrair a difícil tarefa de implementar nestes o paralelismo através da troca de mensagens entre processos em baixo nível. Com esta \API de alto nível, implementar o envio e recebimento de mensagens torna-se algo tão simples como chamar uma função, já que o \MPI abstrai diversas etapas em uma única função. A \API também adiciona identificadores únicos e um grupo de comunicação para cada processo, os quais são usados como parâmetros em diversas de suas funções. Além disso, determinadas funções podem ser executadas de forma síncrona ou assíncrona, aumentando o desempenho da aplicação.

Um fluxo simples de implementação utilizando o \MPI começa com a função \texttt{MPI\_Init()}, que inicia o ambiente de execução \MPI. Na sequência, obtém-se o \textit{id} de um processo através da função \texttt{MPI\_Comm\_rank()}, a qual recebe um comunicador, geralmente o comunicador padrão \texttt{MPI\_COMM\_WORLD} que inclui todos os processos \MPI, como primeiro parâmetro e o endereço da variável que será armazenado o \textit{id} do processo como segundo. Também é possível obter o número máximo de processos em um grupo de comunicação através da função \texttt{MPI\_Comm\_size()}, a qual recebe no primeiro parâmetro um comunicador e no segundo o endereço da variável em que será armazenado este número. Além disso, existem as funções de envio e recebimento de mensagens, \texttt{MPI\_Send()} e \texttt{MPI\_Recv()}, as quais recebem parâmetros como o \textit{buffer} de dados sobre o qual será realizado a leitura ou armazenamento da mensagem, a quantidade de dados, o tipo do dado e o \textit{id} do processo que realizará o envio ou recebimento da mensagem, além de alguns parâmetros adicionais. Por fim, a função \texttt{MPI\_Finalize()} termina a execução do ambiente \MPI.

Ao contrário das funções \texttt{MPI\_Recv()} e \texttt{MPI\_Send()}, que são voltadas para comunicação entre dois processos, funções como \texttt{MPI\_Bcast()} e \texttt{MPI\_Barrier()} são feitas para que haja comunicação entre um grupo de processos. Com a \texttt{MPI\_Bcast()} define-se o envio de uma mensagem de um processo para todos os outros processos associados a um grupo de comunicação. Já com a \texttt{MPI\_Barrier()} cria-se uma barreira, onde um certo processo, ao chegar nesta barreira, aguarda todos os outros processos de um grupo de comunicação chegarem nela antes de continuar sua execução.

O Código \ref{lst:programmpi} mostra um exemplo de implementação simples usando o \MPI. Neste exemplo, na linha 10 o processo com \textit{id} igual a 0 envia um \textit{broadcast} para todos os outros processos, os quais respondem na linha 14 ao processo de \textit{id} 0, que recebe estas respostas nas linhas 16-18. É importante notar que as linhas 16-18 são executadas somente pelo processo com \textit{id} igual a 0, enquanto que as linhas 13-14 são executadas por processos com \textit{id} maior que 0.

\subsection{Bibliotecas específicas para o \mppa}
\label{sec:bibliotecasespecificasmppa}

Na arquitetura do \mppa, os \clusters de \IO gerenciam os \CCs, em um modelo conhecido como mestre/escravo, como exemplificado na Figura \ref{fig:masterslave}. os \CCs e \clusters de \IO executam binários diferentes e fornecem algumas abstrações distintas de programação. Ao ativar um \cluster, associa-se um processo a ele, logo, a inicialização de \CCs acontece através de um processo mestre citando explicitamente em sua implementação o caminho do código binário que será executado no \CC. Cada processo escravo pode criar até 16 \threads do tipo POSIX, cada uma sendo executada em um núcleo diferente dentro daquele \cluster. A criação de \threads nos \CCs pode ser feita explicitamente com uso de POSIX \textit{threads} ou de maneira transparente com uso do \OpenMP. Infelizmente, o \textit{runtime} do \mppa não fornece uma implementação do \MPI para comunicação entre \CCs. Portanto, é necessário utilizar, neste caso, interfaces de programação proprietárias, como \IPC e, mais recentemente, \ASYNC.

\begin{figure}[tb]
  \centering
  \caption{Fluxo de uma aplicação seguindo o modelo \textit{mestre/escravo} no \mppa.}
  \label{fig:masterslave}
  \includegraphics[width=.4\linewidth, keepaspectratio]{mppamasterslave.pdf}
  \fonte{Documentação do MPPA sobre IPC.}
\end{figure}

Com a \IPC, um processo mestre em execução em um dos quatro \clusters de \IO pode lançar outros processos nos \CCs passando argumentos tradicionais, como \texttt{argc} e \texttt{argv}. Porém, toda a lógica de comunicação e sincronização sobre a rede \NoC é abstraída através da realização de operações sobre descritores de arquivos e através do uso das diretivas do padrão POSIX IPC. O \textit{design} da API é baseado no modelo \textit{pipe-and-filters} \cite{softwarecomponentmodels}, onde os processos POSIX são os componentes atômicos e os objetos de comunicação são as conexões. Além disso, os objetos de comunicação possuem portas de transmissão e recepção de dados, chamadas de portais, as quais são abertas em dois possíveis modos, \texttt{O\_WRONLY} (somente escrita) ou \texttt{O\_RDONLY} (somente leitura), através da função \texttt{mppa\_open()}, que recebe no primeiro parâmetro o \textit{path} para o descritor de arquivo de um determinado portal e no segundo o modo no qual será aberto.

Abrindo portais de comunicação específicos para cada \cluster, um para leitura e outro para escrita, e definindo quais \clusters ficarão em cada ponta desses portais, pode-se implementar uma aplicação que segue um fluxo semelhante à Figura \ref{fig:mppaipcflow}. Nela, o processo mestre lança dois processos escravos, os quais abrem portais que definem um caminho para o \cluster que os lançou. Um destes processos não faz uso da função \texttt{mppa\_read()} pois recebeu todos os dados necessários através dos parâmetros passados pelo processo de \IO na chamada a função \texttt{mppa\_spawn()}. Assim, este processo só precisa realizar a computação sobre aqueles dados e devolver o resultado para o \cluster de \IO através do portal que os liga, usando a função \texttt{mppa\_write()}. Já o outro \cluster faz uso da função \texttt{mppa\_read()} para ler dados enviados pelo processo mestre, mas não envia de volta nenhuma informação. Após realizar suas tarefas, os \CCs precisam fechar os descritores de arquivo dos portais que foram abertos e usados, o que é feito através da função \texttt{mppa\_close()}. Por fim, o processo mestre precisa esperar o término da execução dos processos escravos antes de continuar a sua execução, o que é feito com a função \texttt{mppa\_waitpid()}.

\begin{figure}[tb]
  \centering
  \caption{Fluxo de uma aplicação usando funções do tipo POSIX da IPC no \mppa.}
  \label{fig:mppaipcflow}
  \includegraphics[width=.6\linewidth, keepaspectratio]{mppaipcflow.pdf}
  \fonte{Documentação do MPPA sobre IPC.}
\end{figure}

Tendo em vista a complexidade envolvida na utilização da \API \IPC, a fabricante do \mppa desenvolveu recentemente uma nova \API que fornece uma maior abstração e facilidade de programação, denominada \ASYNC.
Baseada em princípios de comunicação unilateral, os quais são aplicados em diversas \APIs usadas em supercomputadores, como a \API PNNL ARMCI \cite{armciapproach}, a \ASYNC é organizada em diversos conceitos que permitem abstrair ainda mais a implementação de paralelismo no \mppa. Dentre esses conceitos, pode-se citar três mais importantes: \textbf{(i)} segmentos de memória, ou seja, memória que não é diretamente acessível através de um dos núcleos de um \cluster; \textbf{(ii)} operações \texttt{PUT/GET}, as quais possuem diversos modos de realização, como linear, espaçada, por etapas e em blocos 2D ou 3D; e \textbf{(iii)} o modo assíncrono como as operações \texttt{PUT/GET} são realizadas, significando que essas funções retornam assim que completam a escrita ou leitura sobre uma porção de memória, não realizando qualquer tipo de sincronização com algum possível \textit{cluster} que irá receber aquela informação.
 
\begin{figure}[tb]
  \centering
  \caption{Fluxo de uma aplicação usando a API ASYNC no \mppa.}
  \label{fig:mppaasyncflow}
  \includegraphics[width=.6\linewidth, keepaspectratio]{mppaasyncflow.pdf}
  \fonte{o autor.}
\end{figure}

Na Figura \ref{fig:mppaasyncflow}, onde os \clusters são representados por quadrados amarelos, é demonstrado o fluxo de implementação do paralelismo entre um processo mestre e um \CC ao usar a \ASYNC. Primeiramente um \cluster de \IO cria um segmento sobre uma porção de dados localizados na sua memória local através da função \texttt{mppa\_async\_segment\_create()}, associando a ele um identificador único do tipo \texttt{unsigned long long}. Após a criação do segmento, um \cluster de computação deve clonar esse segmento através da função \texttt{mppa\_async\_segment\_clone()}, usando, entre outros parâmetros, o identificador do segmento desejado. Chamadas essas duas funções, operações do tipo \texttt{PUT/GET} podem ser realizadas sobre o segmento através das funções \texttt{mppa\_async\_put()} e \texttt{mppa\_async\_get()}. Além das operações mostradas na figura, é preciso inicializar o contexto antes de realizar qualquer uma dessas operações, o que é feito com a função \texttt{mppa\_async\_init()}, e finalizar este contexto após realizar todas as operações necessárias, o que é feito com a função \texttt{mppa\_async\_final()}.

Operações \texttt{PUT} devem ser feitas com cuidado, caso contrário podem sobrescrever operações anteriores que ainda não foram lidas por algum \cluster. Na versão \ASYNC do \capb, sincronizações são feitas através de operações \texttt{poke} sobre um segmento padrão construído na inicialização do contexto da \API. Essas sincronizações são definidas através de macros, que são expandidas para chamadas as funções \texttt{mppa\_async\_poke()} e \texttt{mppa\_async\_evalcond()}, as quais, respectivamente, alteram um valor remoto do tipo \texttt{long long} e aguardam uma expressão booleana se tornar verdadeira antes de continuar a execução. Os Códigos \ref{lst:macrossyncio} e \ref{lst:macrossynccc} mostram como são definidas essas macros em um \cluster de \IO e em um \CC, respectivamente.

\begin{listing}[tb]
\caption{Definição das macros de sincronização em um \cluster de E/S.}
\label{lst:macrossyncio}
\begin{minted}{c}
/* Synchronization between slaves and IO. */
#define send_signal(i)                                     \
poke(mppa_async_default_segment((i)), sig_offsets[(i)], 1) \

/* Synchronization between slaves and IO. */
#define wait_signal(i) {                                           \
waitCondition(&cluster_signals[(i)], 1, MPPA_ASYNC_COND_EQ, NULL); \
cluster_signals[(i)] = 0;                                          \
}   
\end{minted}
\fonte{o autor.}
\end{listing}

\begin{listing}[tb]
\caption{Definição das macros de sincronização em um \cluster de computação.}
\label{lst:macrossynccc}
\begin{minted}{c}
/* Synchronization between slaves and IO. */
#define send_signal()                        \
poke(MPPA_ASYNC_DDR_0, sigback_offset, 1) \

/* Synchronization between slaves and IO. */
#define wait_signal() {                                 \
waitCondition(&io_signal, 1, MPPA_ASYNC_COND_EQ, NULL); \
io_signal = 0;                                          \
}     
\end{minted}
\fonte{o autor.}
\end{listing}

\chapter{Trabalhos Correlatos}
\label{ch:trabcorrelatos}

O tema central deste trabalho é de grande interesse por parte da comunidade científica de \HPC, existindo inúmeras pesquisas voltadas a medir o desempenho de processadores \multicore, \manycore e \chips \FPGA, as quais são diretamente relacionadas a esta. Neste capítulo serão apresentados algumas pesquisas científicas voltadas a medição de parâmetros de desempenho de processadores que utilizam uma dessas duas arquiteturas.

\textit{Nabi} \etal \cite{nabifpgabenchmark} implementaram uma versão do \bench STREAM para arquiteturas \FPGA, \GPUs e \CPUs, chamando-o de STREAM-Multiplataforma, para dar foco a portabilidade de sua versão. O \bench STREAM original foi desenvolvido em 1995 por \textit{McCalpin} \etal \cite{mccalpinstreambench} e é um dos \benchs mais utilizados para medir a largura de banda da memória em computadores. A principal contribuição deste trabalho é a introdução de um \bench que faça esse tipo de medição em dispositivos \FPGA, já que faltam \benchs desse tipo para estes dispositivos. Além disso, parâmetros genéricos e específicos para certas arquiteturas foram introduzidos na nova versão, os quais afetam diretamente a largura de banda da memória. Os autores afirmam que, sendo esta largura de banda um dos principais gargalos das aplicações \HPC \cite{asanoviclandscapeparallel}, este \bench possibilita mais um passo na direção de tornar convencional o uso de placas \FPGA.

Já \textit{Bennett} \etal \cite{bennettqcdbench} desenvolveram um \bench para avaliar a aptidão de um supercomputador ao executar simulações de modelos da física quântica que vão além do modelo padrão. Grande parte dos \benchs dessa área são derivados do modelo \textit{Quantum ChromoDynamics (QCD)}, que descreve a forte interação entre \textit{quarks} e \textit{gluons}. Porém, este modelo não tem a flexibilidade necessária para examinar outros que o estendem, como é o caso dos modelos da Teoria de Gauge, que inclui o QCD. Assim, a inovação deste \bench é ser derivado de implementações que simulam modelos da Teoria de Gauge, que é mais extensa. 

Dentre os \benchs clássicos da comunidade de \HPC, o \textit{NAS Parallel Benchmark} \cite{baileynasbench} se destaca por ter sido concebido puramente através de algoritmos, descrito por seus autores como um \bench com especificação de papel e caneta. Segundos os autores, optar por este caminho é uma maneira de evitar grande parte das dificuldades que uma implementação convencional de um \bench para sistemas \HPC enfrenta. Originalmente 7 \kernels foram descritos para o NAS, os quais simulam diferentes cargas de trabalho encontradas em aplicações \HPC. Todos estes \kernels usam ou uma \API de comunicação entre processos, como a \MPI, ou uma \API para sistemas com memória compartilhada, como a \OpenMP.

Outro \bench clássico para aplicações CUDA + \MPI é o OMB-GPU \cite{bureddyomb}, que estende o \textit{OSU Micro-Benchmarks (OMB)} adicionando \kernels que avaliam a performance de comunicações \MPI em sistemas de \clusters de \GPUs. O OMB-GPU surgiu durante o crescimento no uso de \GPUs em supercomputadores, devido a necessidade de um \bench padronizado para avaliar as novas bibliotecas \MPI que foram desenvolvidas para suportar comunicações \MPI nesses novos sistemas. Com o desenvolvimento da \UM para aplicações CUDA (tecnologia que mescla \textit{software} e \textit{hardware} para criar um espaço de endereço único e acessível por qualquer \GPU ou \CPU de um sistema), houve a necessidade de um novo \bench específico para os sistemas que passaram a utilizar essa tecnologia, já que os \benchs clássicos da época, como o OMB ou o OMB-GPU, não eram aptos para isso, pois não capturavam corretamente o comportamento do driver CUDA neste novo contexto. Assim, \textit{Manian} \etal desenvolveram o OMB-UM \cite{maniancudaum}, uma extensão do OMB para suportar aplicações CUDA + \MPI + \UM.

Diferentemente dos \benchs anteriores, \textit{Kelly} \etal \cite{kellynwsc} desenvolveram o \bench NWSC para testar um supercomputador especifico, o \textit{NCAR-Wyoming Supercomputing Center (NWSC)}, que estava sendo construído para suprir as necessidades computacionais de aplicações \HPC de 5 domínios científicos: \textbf{(i)} Física Atmosférica; \textbf{(ii)} Clima Espacial; \textbf{(iii)} Oceanografia; \textbf{(iv)} Modelagem de Subsuperfícies; e \textbf{(v)} Ciência Computacional, Estatística e Matemática. Este supercomputador seria o próximo sistema \HPC do Centro Nacional de Pesquisas Atmosféricas dos Estados Unidos, suportando grande parte da necessidade de poder computacional da comunidade científica de \HPC, logo, viu-se a necessidade de construção de um \bench específico para avaliá-lo.

Dentre as mais recentes pesquisas voltadas ao desenvolvimento de \benchs para a área de \HPC temos o Mirovia, um \bench desenvolvido por \textit{Hu} \etal \cite{miroviabenchmark} para tirar proveito de arquiteturas de \GPUs modernas, medindo de forma precisa os atuais sistemas heterogêneos, com processadores \multicore, \manycore e \GPUs. O Mirovia foi desenvolvido na necessidade de um \bench que levasse em conta as novas tecnologias que esses sistemas possuem, como a memória unificada, já que os \benchs clássicos, como o Rodinia \cite{rodiniabench} ou o SHOC \cite{shocbench}, foram desenvolvidos antes do surgimento destas. Além disso, devido ao crescente interesse em redes neurais e aprendizagem profunda, alguns \kernels com foco nesta área foram adicionados. Assim, o Mirovia tem como base \kernels de \benchs clássicos e adiciona \kernels de aplicações de maior interesse atual para melhor caracterizar os sistemas heterogêneos modernos.

Por fim, \textit{Tian} \etal \cite{tianbench} desenvolveram o BigDataBench-S, um \bench que avalia a performance de sistemas de gerenciamento de \textit{bBig Data}. Os autores ressaltam que o número de dados gerados por aplicações científicas é cada vez maior e que os atuais \benchs desse contexto foram feitos para sistemas que focam ou na Internet ou em alguma área científica específica. Assim, o BigDataBench-S surge como um \bench representativo para avaliar os sistemas de gerenciamento e análise de dados gerados por aplicações, equipamentos e dispositivos de propósito científico.

Nenhum dos \textit{benchmarks} descritos anteriormente foi desenvolvido com foco em \textit{manycores} de baixa potência, como o \mppa. Nesse sentido, o \capb~\cite{Castro-Souza-CCPE:2016} é o único \textit{benchmark} conhecido para esse processador, permitindo exercitar diferentes funcionalidades dele. Até então, o \capb era implementado com a \API \IPC do \mppa~\cite{mppa2562013}. No próximo capítulo será discutido como o \capb foi modificado para funcionar com a nova \API \ASYNC do \mppa. Esta nova versão do \capb é a principal contribuição do presente trabalho.

\chapter{Desenvolvimento}
\label{ch:desenvolvimento}

Para a realização deste trabalho, foram feitos dois tipos de alteração em todas as aplicações do \capb. Primeiro, criou-se uma nova versão de cada aplicação, na qual foram realizadas modificações em sua lógica de processamento para que pudesse utilizar a \API \ASYNC. Após isso, alterou-se as versões antigas, que usam a \API \IPC, para que ficassem equivalente as novas aplicações em relação ao seu fluxo de processamento. Nesta seção serão mostradas todas as alterações feitas em cada aplicação e em cada etapa. Uma descrição mais detalhada de cada um dos \kernels pode ser encontrada no trabalho de \textit{Souza} \etal \cite{Castro-Souza-CCPE:2016}.

\section{Alterações na Friendly Numbers}
\label{sec:alteracoesfn}

Segundo a teoria dos números, dois números naturais e inteiros são amigáveis se compartilham a mesma abundância. A abundancia $\mathnormal{A}$ de um número $\mathnormal{n}$ é definida como $\mathnormal{A(n) = \frac{\sigma(b)}{n}}$, onde $\sigma(n)$ representa a soma de todos os divisores de n. A aplicação \textit{\FN} calcula e compara as abundâncias de todos os números em um certo intervalo, determinando quais pares de números são amigáveis. O padrão paralelo usado nessa aplicação é o \textit{MapReduce}.

A primeira aplicação portada com a \ASYNC foi a \textit{\FN}, tendo pequenas alterações devido a sua baixa complexidade. Em ambas as versões, existe um \textit{array} de tamanho fixo que define as tarefas de cada \cluster segundo intervalos de \offsets, onde em cada posição existem três variáveis do tipo \texttt{int} agrupadas em uma \texttt{struct}. Basicamente, o \cluster de \IO define um intervalo de números e seta cada número na variável \texttt{number} de cada \texttt{struct}, enquanto que os \CCs devem calcular as variáveis \texttt{num} e \texttt{den}. O Código \ref{lst:structitemtask} detalha como é feita a implementação de ambos \textit{array} e \texttt{struct}.

\begin{listing}[h]
\caption{Definição das taréfas por  parte do \cluster de IO.}
\label{lst:structitemtask}
\begin{minted}{c}
/* Items to be sent to slaves */
typedef struct {
    int number; /* Number    */
    int num;  /* Numerator   */
    int den;  /* Denominator */
} Item;    

#define MAX_TASK_SIZE 65536

static Item tasks[MAX_TASK_SIZE];
\end{minted}
\fonte{o autor.}
\end{listing}

A versão \ASYNC possibilitou a redução de grande parte do fluxo de operações desta aplicação. Anteriormente, era necessário explicitamente realizar operações de envio e recebimento de mensagens no \cluster de \IO, através das macros \texttt{data\_send()} e \texttt{data\_receive()}, sendo essas operações totalmente bloqueantes. Com a introdução dos segmentos pela \API \ASYNC, duas linhas de código substituem ambas operações. Nesse caso, um segmento é criado através da função \texttt{mppa\_async\_segment\_create()}, sobre o \textit{array} de tarefas. Assim, qualquer \CC que cloná-lo poderá acessar seu conteúdo e modificá-lo, sendo essas modificações totalmente acessíveis ao cluster de \IO através do mesmo \textit{array} de tarefas.

Dessa maneira, os \CCs só são lançados depois que todas as tarefas estão definidas no \textit{array} e o segmento foi criado. Então, um \cluster de computação só precisa fazer uma operação \texttt{GET} em um certo intervalo no segmento, processar os dados, e enviá-los de volta através de uma operação \texttt{PUT} no mesmo intervalo no segmento. Como cada \CC possui um intervalo de \offsets diferente, não há sobreposição de tarefas e não existe nenhuma condição de corrida sobre uma certa posição no segmento. Por fim, como as operações \texttt{PUT} dos \CCs alteram o \textit{array} no qual o segmento foi definido no \cluster de \IO, não há necessidade do processo \master realizar um \texttt{GET} sobre aquele segmento, bastando acessar o \textit{array} de tarefas diretamente. Logicamente, se o processo \master ler o \textit{array} antes da hora, irá obter valores \texttt{null} para as variáveis \texttt{num} e \texttt{den}, logo, é feita uma única sincronização, onde os \clusters de \IO aguardam a sinalização dos \CCs de que determinada tarefa já foi computada e colocada em um certo intervalo do segmento, antes de ler aquele intervalo.

Mudanças sem relação com as \APIs também foram implementadas em ambas as versões. No código dos \slaves, existe uma função que computa a soma dos divisores de um número. Nesta função, era feito um \textit{loop} iniciando em 2 e terminando no número, onde em cada iteração verifica-se se o número daquela iteração era divisor do número passado como argumento para a função. Com a otimização, alterou-se o \textit{loop} para iterar até metade do número passado como argumento, já que, acima da metade, o único divisor de um número é ele mesmo. Outra otimização feita foi em relação ao paralelismo para verificar quais números tinham as variáveis \texttt{num} e \texttt{den} iguais. Na versão antiga utilizou-se \textit{POSIX Threads} para fazer uma soma parcial e depois uma redução na \textit{thread} principal, gastando mais de 50 linhas nessa lógica. Na nova versão, com a utilização de diretivas do \OpenMP, reduziu-se essas 50 linhas em 5, com um fluxo de execução muito mais fácil de ser entendido.

\section{Alterações na Features from Accelerated Segment Test}
\label{sec:alteracoesfast}

\textit{\FAST} é um algoritmo de detecção de cantos que segue o padrão paralelo \textit{Stencil}. Esse algoritmo é muito usado para extrair pontos importantes em uma imagem, assim como mapear objetos em aplicações de visão computacional. O algoritmo usa um círculo de 16 \textit{pixels} para testar se um certo ponto $\mathnormal{p}$ é um canto. Cada \textit{pixel} no círculo é classificado através de um inteiro que varia de 1 a 16. Se todos os $\mathnormal{N}$ \textit{pixels} do círculo possuírem um brilho maior do que o do candidato.

A versão antiga da \textit{\FAST} sofreu otimizações em partes que ocupavam a maior porcentagem do seu tempo de execução. Nesta versão, o \cluster de \IO realizava o envio de tarefas aos \CCs através de iterações em um \texttt{for}, enquanto que os \CCs aguardavam as tarefas em um \texttt{while(true)}, recebendo, primeiramente, uma mensagem sinalizando se naquela iteração era necessário computar algo ou se poderia encerrar sua execução. Porém, como todas as variáveis utilizadas no \texttt{for} do processo \master poderiam ser passadas como argumento no momento de lançar um \CC, foi implementado isso em ambas as novas versões, o que resultou na eliminação de toda a lógica de enviar uma mensagem ao \slave para sinalizar se este deve ou não continuar sua execução. Assim, implementou-se um \texttt{for} com início e fim bem definidos no código do \slave, eliminando o \texttt{while(true)} deste e reduzindo de quatro para uma o número de mensagens que os \slaves recebem por iteração. Além disso, em ambas versões, reduziu-se de dois para um o número de mensagens enviadas dos \slaves para o \master por iteração, pois na nova versão, em vez de retornar a cada iteração ambos o número de cantos detectados e parte da nova imagem, só é retornado o segundo, somando o primeiro em cada iteração e o retornando ao fim de todas elas.

Na versão \ASYNC foram criados 3 segmentos sobre os dados necessários para os \slaves. Primeiro, um segmento sobre a máscara a ser aplicada na imagem que se quer detectar os cantos, o qual todos os \CCs tem acesso completo. Em seguida, um sobre a imagem original e um sobre o \textit{array} que irá conter o resultado do filtro aplicado a esta imagem, os quais os \CCs só tem acesso a uma lista de intervalos de \offsets. Assim, nesta versão a otimização é ainda melhor, pois com toda a abstração que os segmentos trazem, a troca de mensagens cai pela metade, já que somente os \slaves precisam realizar operações \texttt{PUT} e \texttt{GET}, bastando ao \master criar os segmentos sobre os dados. Além disso, com as otimizações do parágrafo anterior, os \slaves agora sabem exatamente o número de operações que devem executar e, como conhecem os intervalos de \offsets que podem acessar dentro dos segmentos da imagem original e imagem filtrada, são totalmente autônomos para pegar e responder as tarefas nestes segmentos de forma totalmente assíncrona e paralela. Essa autonomia também se dá pois estes intervalos são diferentes para todos os \slaves, não havendo a repetição de nenhum intervalo em dois \CCs distintos, o que elimina a possibilidade de condições de corrida e permite um paralelismo com eficiência máxima.

\section{Alterações na Gausian Filter}
\label{sec:alteracoesgf}

Em resumo, o algoritmo \textit{Gaussian blur filter} aplica um filtro de suavização em determinada imagem, buscando reduzir seu ruído e alcançar uma imagem mais suave. Para isso, uma máscara bidimensional previamente computada é aplicada sobre uma imagem através de uma operação com uma matriz de convolução. O padrão paralelo desta aplicação é o \textit{Stencil}.

Poucas foram as alterações da \textit{\GF}, sendo esta a aplicação com menos modificações, dentre todas as outras. Quanto a versão \IPC, nada foi modificado. Já a versão \ASYNC seguiu a mesma lógica da versão \IPC, substituindo as chamadas das funções síncronas de envio e recebimento de mensagens para chamadas as funções assíncronas de \texttt{PUT} e \texttt{GET}. Para realizar esta substituição, foram criados dois segmentos de dados, sendo um sobre o \textit{array} que guarda a máscara a ser aplicada na imagem e outro sobre o \textit{array} que guarda o pedaço da imagem a ser trabalhado em determinada iteração, chamado de \textit{chunk}. Ambos podem ser completamente acessados pelos \slaves, porém, no segundo só é feito um acesso por vez. Assim, o método de comunicação de dados sobre este segmento é separado em duas etapas, as quais, dependendo do tamanho da imagem a ser aplicada o filtro, podem ou não acontecer diversas vezes durante a execução da aplicação. 

Na primeira etapa, o \cluster de \IO realiza somente escritas sobre o segmento, onde cada escrita é seguida de uma leitura por algum \CC, o qual armazena o que foi lido em sua memória local e sinaliza ao processo \master para prosseguir com a inserção da próxima tarefa para o próximo \CC. Já na segunda etapa, após terem feito toda computação sobre o \textit{chunk} que receberam, os \CCs aguardam o processo \master sinalizar que está na hora de escrever o dado calculado sobre o mesmo segmento em que foi recebido o \textit{chunk}, e, quando sinalizados, escrevem-no. Enquanto isso, o \cluster de \IO aguarda cada \CC sinalizar que tal dado já foi escrito no segmento. Apesar de complexo, este método é ligeiramente melhor que o da versão \IPC, visto que as operações \texttt{PUT} e \texttt{GET} de envio e recebimento de mensagens só são realizadas no lado dos \clusters de computação, já que no processo \master só é necessário copiar o dado do segmento para algum lugar dentro do \textit{array} que irá conter a nova imagem. Assim, similar às demais aplicações, a troca de mensagens é reduzida pela metade.

\section{Alterações na LU Factorization}
\label{sec:alteracoeslu}

A aplicação com maior número de modificações em sua lógica foi a \textit{\LU}, principalmente por causa da implementação errônea do algoritmo na primeira versão. Basicamente, o algoritmo de decomposição LU transforma uma matriz $\mathnormal{A}$ em duas matrizes, uma triangular inferior ($\mathnormal{L}$) e uma triangular superior ($\mathnormal{U}$), de modo que $\mathnormal{A = L * U}$. Porém, o erro da primeira versão foi implementar permutações de trocas de linha e coluna, as quais caracterizam outra decomposição, chamada de PLU e definida pela equação $\mathnormal{P * A = L * U}$, onde $\mathnormal{P}$ é o agregado final de todas as matrizes de permutação aplicadas sobre A. Assim, funções de percorriam extensivamente a matriz em busca de um novo pivô e funções que trocavam linhas e colunas foram removidas. Além disso, blocos dentro da matriz eram enviados de forma errada aos \slaves, gerando um resultado final totalmente errado. A Figura \ref{fig:rightandwrongblocks} mostra como um bloco de 9 elementos (3x3) deveria ser passado, segundo a matriz $\mathnormal{B}$, e como era passado primeira versão, segundo a matriz {A} (os blocos estão pintados em vermelho). Vale salientar que esse erro só foi possível pois a variável que guarda a matriz na verdade é um \textit{array} unidimensional.

\begin{figure}[h]
  \centering
  \caption{Exemplo de um bloco passado a um \slave em cada versão da LU.}
  \label{fig:rightandwrongblocks}
  \[
    A=
    \begin{bmatrix}
      1  & 5  & 3  & 8  \\
      12 & \color{red} 7  & \color{red} 15 & \color{red} 12 \\
      \color{red}  3  & \color{red}  12 & \color{red}  92 & \color{red} 8 \\
      \color{red}  6  & \color{red}  9  & 3  & 1 
    \end{bmatrix}\quad
    B=
    \begin{bmatrix}
      1  & 5  & 3  & 8  \\
      12 & \color{red} 7  & \color{red} 15 & \color{red} 12 \\
      3  & \color{red} 12 & \color{red} 92 & \color{red} 8 \\
      6  & \color{red} 9  & \color{red} 3  & \color{red} 1 
    \end{bmatrix}
  \]
\end{figure}

Todos os erros citados no parágrafo anterior foram solucionados em ambas as versões. Quanto a versão \ASYNC, para tirar proveito desta \API foi criado um segmento sobre a matriz original e um segmento sobre um \textit{array} de tarefas. Deste modo, em uma certa iteração, um processo \slave consulta o segmento de tarefas usando seu próprio \textit{id} como \offset, recuperando um tarefa que contém, entre outras variáveis, os \offsets que serão aplicados para pegar um bloco no segmento da matriz. Quando um \CC não possui mais tarefas, o \cluster de \IO coloca uma mensagem de finalização no \offset deste \slave dentro do segmento de tarefas, o qual a recebe e finaliza sua execução. Devido aos dois segmentos citados acima, as operações \texttt{PUT} e \texttt{GET} são feitas somente pelos \CCs, enquanto que o processo \master só realiza sinalizações, quando coloca uma tarefa no segmento, e sincronizações, quando todos os \slaves finalizam uma iteração de computação.

\section{Alterações na K-Means}
\label{sec:alteracoeskm}

\textit{\KM} é um algoritmo de clusterização de dados muito usado na área de análise de dados. Dado um conjunto de $\mathnormal{n}$ pontos em um espaço de dimensão $\mathnormal{d}$, o problema passa por particionar estes $\mathnormal{n}$ pontos em $\mathnormal{k}$ conjuntos. No \capb, os pontos são inicializados com coordenadas aleatorias e divididos aleatoriamente entre as $\mathnormal{k}$ partições. Assim, os \textit{centroids} iniciais são computados (um \textit{centroid} representa a média de todos os pontos de uma partição $\mathnormal{k}$), os pontos são novamente divididos entre as partições levando em conta a distância mínima euclidiana entre cada ponto e o \textit{centroid} da sua partição e, por fim, os \textit{centroids} são recalculados. Todo esse procedimento é repetido até que nenhum \textit{centroid} mude de posição. Durante a execução, o número de pontos em cada partição pode variar, implicando em diferentes tempos de computação para cada \textit{centroid} de cada partição. O padrão paralelo da \KM é o \textit{Map}.

Diversas simplificações na lógica do \kernel \KM foram feitas. Primeiramente, devido a grande quantidade de dados enviados aos \CCs e a diferença nos tipos destes dados, resolveu-se adotar uma nova estratégia, desta vez utilizando o segmento padrão \texttt{MPPA\_ASYNC\_DDR\_0}, que é sempre criado na inicialização da \ASYNC, para o envio destes. Desta forma, através da função \texttt{mppa\_async\_malloc()}, cada \slave aloca uma porção de memória neste segmento para cada uma das variáveis que vão utilizar em suas iterações e comunicações. Esta função então retorna um \offset apontando para onde aquele espaço foi alocado dentro do segmento, e todos os \offsets são enviados para o processo \master, através de outro segmento especialmente criado para isso. Ao término desta primeira etapa, o processo \master saberá onde ler e escrever todos os dados no segmento padrão e, em etapas subsequentes, todas as comunicações dos dados computados serão feitas neste segmento, utilizando estes \offsets.

Pensando na otimização do envio e recebimento dos dados em cada iteração, o modelo de dados da aplicação também foi simplificado. Na versão original, os pontos eram definidos como \texttt{structs}, chamadas de vetores, contendo o tamanho (dimensão do vetor) e um ponteiro para os elementos (coordenadas do vetor). Porém, como todos os vetores possuem o mesmo tamanho, já que a dimensão é tratada globalmente, foi possível otimizar este modelo, inicializando todos os pontos em unico \textit{array} unidimensional. Desse modo, em um cenário com P pontos, todos com dimensão $\mathnormal{X}$, cada ponto ocupa $\mathnormal{X}$ posições do \textit{array} e o tamanho total deste é de $\mathnormal{X * P}$ posições. Logo, fica muito mais fácil separar os pontos em intervalos e enviar cada intervalo como tarefa para um certo \cluster de computação.

Por fim, a lógica de cálculo dos \textit{centroids} (média dos elementos de um certo grupo) também foi alterada. Na versão original, toda a computação do cálculo da distância euclidiana média era feita nos \CCs. Isto requeria que os \CCs enviassem a informação sobre suas populações parciais (número de elementos de um grupo) para o processo \master, que na sequência os enviava de volta a soma destes dados. Já na nova versão, nos \CCs é realizado somente a primeira etapa deste cálculo (a soma dos vetores parciais). Para calcular a média destes vetores, a população total é necessária, a qual está facilmente disponível no processo \master após determinada iteração. Assim, o cálculo da média é feito no \cluster de \IO, o que resulta em menos comunicações feitas entre os processos, gerando uma redução de 2 operações de escrita e 2 operações de leitura por iteração.

\section{Alterações na Integer-Sort}
\label{sec:alteracoesis}

\IS é um algoritmo que soluciona o problema de ordenar um grande número de inteiros. A variação do algoritmo implementado no \capb foi o \textit{bucket-sort}, o qual divide os elementos a serem ordenador em baldes. Um balde é uma estrutura que armazena uma certa quantidade de inteiros. A inicialização da aplicação se dá com entradas aleatórias para o conjunto dos inteiros, os quais são gerados em um intervalo entre $\mathnormal{0}$ até $\mathnormal{2^{20} - 1}$. Por fim, o \IS usa o padrão paralelo Dividir para Conquistar.

A aplicação \textit{\IS} sofreu poucas alterações quanto a sua lógica, otimizando somente a etapa de recebimento dos \textit{buckets} nos \slaves. Na versão antiga, pra qualquer variação da classe de tamanho do problema, a ordenação parcial dos \textit{buckets} era feita sempre com o número máximo de elementos que um \textit{bucket} armazena na maior classe de problema. Como existem 16 núcleos em um determinado \cluster, se o número de elementos de um \textit{bucket} é divisível por 16 a paralelização do trabalho é simplificada, e, como o número máximo de elementos da maior classe abrange todas as classes inferiores e é também divisível por 16, resolveu-se utilizar este. Porém, isso tomava muito tempo da ordenação, já que era preciso iterar sobre uma grande porção de elementos \textit{dummy} no \textit{array} de elementos daquele \textit{bucket}. Na nova versão a ordenação é feita com o número de elementos de um \textit{bucket} somados a, no máximo, 16 novos elementos de valor igual ao máximo inteiro possível. Assim, o número total de elementos sempre será divisível por 16 e as iterações sobre elementos \textit{dummy} não afetam o tempo total de execução da aplicação.

Com a adição da \API \ASYNC, criou-se um segmento sobre o \textit{array} que armazena os \textit{buckets} a serem enviados para os \CCs em determinada iteração. Para enviar um \textit{bucket} a um certo \CC, os elementos deste são colocados no segmento descrito acima, num intervalo de \offsets reservado aquele \CC, enviando um sinal para este \slave de que o dado está pronto para ser computado. Após realizada a ordenação parcial de um determinado \textit{bucket}, os \CCs colocam-o de volta no mesmo intervalo reservado dentro do segmento dos \textit{buckets}, enviando um sinal ao processo \master de que o trabalho foi feito e o dado está pronto.
 
\chapter{Resultados}
\label{ch:resultados}

Este capítulo apresenta os resultados obtidos nas execuções de cada \kernel em cada versão do \capb, comparando-os através de métricas definidas para as duas versões. Dentre as variáveis medidas, são comparadas: \textbf{(i)} o tempo de execução de cada \CC em segundos; \textbf{(ii)} o tempo de execução do processo \master em segundos, excluindo o tempo de envio e recebimento de dados e o tempo em que este se encontra bloqueado; \textbf{(iii)} o tempo gasto durante a transferência de dados entre os processos \master e \slave, também em segundos, incluindo o tempo de sincronização de envio e recebimento de dados, no caso da \IPC, ou da sincronização por meio de barreiras, no caso da \ASYNC; \textbf{(iv)} a quantidade de dados que o processo \master envia para os \slaves, em \textit{megabytes}; \textbf{(v)} a quantidade de dados que o processo \master recebe dos \slaves, também em \textit{megabytes}; \textbf{(vi)} a potência média durante a execução da aplicação, em \textit{watts}; e \textbf{(vii)} o consumo de energia durante a execução da aplicação, em \textit{joules}.

As aplicações foram executadas com as classes de tamanho \textit{tiny}, \textit{small}, \textit{standard}, \textit{large} e \textit{huge}. Para cada classe, variou-se o número de \clusters de computação entre 1, 2, 4, 8 e 16. Além disso, 5 repetições foram realizadas para cada uma dessas variações. Assim, os resultados de cada métrica são sempre a média dessas execuções. Como o \mppa possui características intrínsecas que garantem baixa variabilidade entre as execuções, somente 5 repetições foram suficientes para garantir um desvio padrão relativo menor que 1\% nas métricas de tempo de execução e energia. Todos os experimentos consideram 16 núcleos de processamento ativos por \cluster utilizado. As medições de energia foram coletadas através de sensores de energia e potência espalhados nos diferentes componentes de \textit{hardware} do processador, considerando todos os \clusters, os subsistemas de \IO, a \NoC e a memória. Por fim, ambas versões foram executadas com a \textit{flag} de otimização \texttt{-O3} do GCC.

Cada gráfico mostrado neste capítulo compara determinada métrica de uma aplicação que usa a \API \ASYNC \textit{versus} esta mesma aplicação usando a \API \IPC. Essa comparação é então estendida para cada variação do número de \clusters e para cada variação da classe de tamanho do problema. Para a aplicação \KM, a classe \textit{large} não foi executada com 1 \cluster e a classe \textit{huge} não foi executada com 1 e 2 \clusters, pois segundo a lógica da aplicação, não é possível distribuir o trabalho para os \clusters nesse contexto, já que a memória destes não suporta o tamanho da tarefa que seria enviada em uma certa iteração. Devido ao grande intervalo entre os valores mínimo e máximo de quase todos os gráficos, adotou-se nestes uma escala em potência de 2 para melhor visualização dos resultados. Os gráficos que não possuem este problema utilizam uma escala linear.

Por último, as tabelas deste capítulo exibem a redução ou aumento de determinada métrica através da fórmula $\mathnormal{((Resultado \ASYNC / Resultado \IPC) - 1) * 100}$, mostrando a porcentagem de redução dessa métrica na versão \ASYNC, caso positiva, ou de aumento, caso negativa. Desta maneira, as tabelas focam no melhor e pior resultado de redução, informando em qual variação ocorreu esse resultado, ou seja, em qual classe de problema e com quantos \clusters, disponibilizando também os resultados da medida na versão \IPC e \ASYNC que geraram essa porcentagem.

\section{Resultado das Métricas de Tempo}
\label{sec:metricastempo}

As métricas de tempo mostram um resultado positivo quanto a otimização do \capb utilizando a \API \ASYNC. Para os tempos de execução dos \slaves, houve melhoria em todos os \kernels, com a porcentagem de redução variando entre 57.14 \% até 94.44 \%, conforme mostrado na Tabela \ref{tab:slavetable}. Além disso, essa tabela mostra uma grande consistência na porcentagem de redução de todas as variações de execução, já que a diferença entre a redução mínima e máxima é pequena para todos os \kernels. A Figura \ref{fig:slavetime} mostra os resultados dos tempos de execução dos \slaves.

\begin{table}[h]
\centering
\caption{Reduções ao comparar-se os tempos dos processos \slaves.}
\label{tab:slavetable}
\scalebox{0.65}{
\begin{tabular}{l c c c c c c c c c l}
App & \multicolumn{5}{c}{Redução Mínima} & \multicolumn{5}{c}{Reduçã Máxima}

\\\cmidrule(lr){2-6}\cmidrule(lr){7-11}

& Classe & NClusters & IPC(s) & ASYNC(s) & Redução(\%) & Classe & NClusters & IPC(s) & ASYNC(s) & Redução(\%)\\\midrule

FAST & Tiny & 8 & 0.72 & 0.05 & 93.06 & Tiny & 16 & 0.36 & 0.02 & 94.44 \\
FN & Huge & 1 & 34412.07 & 1952.39 & 94.33 & Small & 16 & 267.9 & 15.14 & 94.35 \\
GF & Tiny & 4 & 1.38 & 0.09 & 93.48 & Tiny & 8 & 0.69 & 0.04 & 94.2 \\ 
IS & Tiny & 8 & 1.82 & 0.78 & 57.14 & Huge & 1 & 282.06 & 115.03 & 59.22 \\
KM & Tiny & 16 & 2.86 & 0.19 & 93.36 & Standard & 1 & 1427.49 & 91.55 & 93.59 \\
LU & Tiny & 2 & 0.28 & 0.09 & 67.86 & Huge & 2 & 40.15 & 9.02 & 77.53 \\

\bottomrule
\end{tabular}}
\end{table}

Já para os tempos de execução do processo \master, houve melhoria em todos os \kernels com exceção do \LU, conforme mostrado na Tabela \ref{tab:mastertable}. A porcentagem de redução variou entre -28.79 \% até 70.2 \%. A variação no número de \clusters só afeta significativamente essa variável na aplicação \KM, visto que este é o único \kernel em que o peso de certas computações no processo \master é consideravelmente influenciado pelo número de \clusters. Além disso, as aplicações \KM e \LU tem uma pequena variação entre os resultados mínimo e máximo, conforme a Figura \ref{fig:mastertime}. Levando isso como argumento, pode-se considerar que esses 2 \kernels obtiveram resultados semelhantes em ambas as versões nessa variável, excluindo a possibilidade do aumento na \LU ser algo negativo, principalmente porque este mesmo \kernel obteve uma boa redução no tempo de execução dos \slaves, segundo a Tabela \ref{tab:slavetable}, e no tempo de comunicação, segundo a Tabela \ref{tab:commtable}. Os \kernels \FAST e \GF não são mostrados nem na tabela nem no gráfico dessa variável, já que ambos não executam computações no processo \master, tornando o resultado dessa variável igual a 0 para estes.

\begin{table}[h]
\centering
\caption{Reduções ao comparar-se os tempos do processo \master.}
\label{tab:mastertable}
\scalebox{0.6}{
\begin{tabular}{l c c c c c c c c c l}
App & \multicolumn{5}{c}{Redução Mínima} & \multicolumn{5}{c}{Reduçã Máxima}

\\\cmidrule(lr){2-6}\cmidrule(lr){7-11}

& Classe & NClusters & IPC(s) & ASYNC(s) & Redução(\%) & Classe & NClusters & IPC(s) & ASYNC(s) & Redução(\%)\\\midrule

FN & Tiny & 1 & 0.14 & 0.08 & 42.86 & Huge & 1 & 118.54 & 35.32 & 70.2 \\
IS & Standard & 1 & 12.27 & 10.96 & 10.68 & Huge & 8 & 56.72 & 46.5 & 18.02 \\
KM & Tiny & 1 & 0.01 & 0.01 & 0.0 & Tiny & 4 & 0.02 & 0.01 & 50.0 \\
LU & Huge & 2 & 0.66 & 0.85 & -28.79 & Tiny & 2 & 0.02 & 0.02 & 0.0 \\

\bottomrule
\end{tabular}}
\end{table}

Por fim, os tempos de comunicação também melhoraram em todos os \kernels com exceção do \IS, o qual obteve aumento nessa variável em todas as classes de problemas ao executar com 8 e 16 \clusters. A Tabela \ref{tab:commtable} mostra que a porcentagem de redução dessa métrica variou entre -213.16 \% até 99.66 \%, porém, a Figura \ref{fig:commtime} mostra que houve melhorias nesse \kernel para todas as outras variações de \clusters. Os gráficos dessa figura mostram também que, diferentemente da \IPC, a \API \ASYNC é mais custosa conforme aumento no número de \clusters, mostrando uma tendência de parábola, a qual consegue ser reduzida até um certo número e, após este, cresce novamente. Conclui-se então que o maior número de \clusters é um fator relevante no tempo de comunicação da \API \ASYNC.

\begin{table}[h]
\centering
\caption{Reduções ao comparar-se os tempos de comunicação.}
\label{tab:commtable}
\scalebox{0.6}{
\begin{tabular}{l c c c c c c c c c l}
App & \multicolumn{5}{c}{Redução Mínima} & \multicolumn{5}{c}{Reduçã Máxima}

\\\cmidrule(lr){2-6}\cmidrule(lr){7-11}

& Classe & NClusters & IPC(s) & ASYNC(s) & Redução(\%) & Classe & NClusters & IPC(s) & ASYNC(s) & Redução(\%)\\\midrule

FAST & Tiny & 16 & 1.44 & 1.16 & 19.44 & Huge & 8 & 109.55 & 1.25 & 98.86 \\
FN & Huge & 1 & 34412.4 & 976.35 & 97.16 & Huge & 16 & 2159.8 & 7.34 & 99.66 \\
GF & Tiny & 16 & 1.31 & 1.1 & 16.03 & Huge & 4 & 1162.81 & 20.57 & 98.23 \\ 
IS & Tiny & 16 & 1.14 & 3.57 & -213.16 & Huge & 1 & 286.46 & 80.34 & 71.95 \\
KM & Tiny & 16 & 3.82 & 1.11 & 70.94 & Huge & 16 & 670.86 & 4.28 & 99.36 \\
LU & Tiny & 16 & 7.22 & 1.36 & 81.16 & Large & 8 & 193.78 & 6.2 & 96.8 \\

\bottomrule
\end{tabular}}
\end{table}

\begin{figure}[h]
  \centering
  \caption{Tempos de execução do processo \master para cada aplicação.}
  \label{fig:mastertime}
  \includegraphics[width=.9\linewidth, keepaspectratio]{master_time.pdf}
\end{figure}

\begin{figure}[h]
  \centering
  \caption{Tempos de execução dos processos \slaves para cada aplicação.}
  \label{fig:slavetime}
  \includegraphics[width=.9\linewidth, keepaspectratio]{slave_time.pdf}
\end{figure}

\clearpage

\begin{figure}[h]
  \centering
  \caption{Tempos de comunicação para cada aplicação.}
  \label{fig:commtime}
  \includegraphics[width=.9\linewidth, keepaspectratio]{comm_time.pdf}
\end{figure}

\clearpage

\section{Resultado das Métricas de Envio e Recebimento de Dados}
\label{sec:metricasdados}

Um fator importante ao comparar-se a similaridade das aplicações em cada versão é a quantidade de dados trocados entre o \cluster de \IO e os \CCs. Nessa análise, os resultados das métricas de envio e recebimento de dados são mostrados somente via gráficos, na Figura \ref{fig:datasent} e \ref{fig:datareceived}, visto que estes já são suficientes para uma prova simplificada de que o peso de execução das aplicações é o mesmo para ambas as versões. Além disso, a tabela de redução mínima e máxima não faz sentido para a maioria das aplicações, já que nestas em todas as variações o resultado foi o mesmo, não havendo máximo ou mínimo.

\begin{figure}[h]
  \centering
  \caption{Quantidade de dados que o processo \master envia aos \slaves.}
  \label{fig:datasent}
  \includegraphics[width=.9\linewidth, keepaspectratio]{data_sent.pdf}
\end{figure}

\clearpage

Duas aplicações são exceções para o que foi afirmado no parágrafo anterior. A \KM obteve resultados com uma redução entre 6.67 \% e 48.51 \% para os dados enviados e entre -1.56 \% e 19.83 \% para os dados recebidos. Já a \LU obteve resultados iguais para todas as classes de problema exceto a \textit{large}, a qual teve uma redução de -100 \% nos dados enviados e -171.88 \% nos dados recebidos. Como as aplicações foram implementadas de modo semelhante em ambas versões, esses resultados são uma grande indicação de que, na versão \ASYNC dessas duas aplicações, pode existir \textit{bugs} em relação a medição dessa variável, mesmo não tendo sido encontrados após reanálise. Assim, tomam-se esses resultados como verdadeiros. Em conclusão, vale ressaltar a importância dessa métrica na busca por \textit{bugs} em futuras aplicações no \mppa.

\begin{figure}[h]
  \centering
  \caption{Quantidade de dados que o processo \master recebe dos \slaves.}
  \label{fig:datareceived}
  \includegraphics[width=.9\linewidth, keepaspectratio]{data_received.pdf}
\end{figure}

\clearpage

\section{Resultado das Métricas de Energia}
\label{sec:metricasenergia}

As métricas de energia confirmam o que foi observado na Seção \ref{sec:metricastempo} deste capítulo. Realmente a \API \ASYNC é mais custosa conforme o aumento no número de \clusters, contudo, a \IPC também apresenta esse comportamento. A Tabela \ref{tab:avgpower} mostra que a potência média de execução das aplicações é maior na grande maioria das variações, o que é confirmado pela Figura \ref{fig:avgpower}. A redução dessa variável foi de -132.57 \% até 3.75 \%. De fato, a \ASYNC é mais custosa do que a \IPC nessa métrica pois aloca mais recursos do processador para gerenciar toda a abstração que proporciona.

\begin{table}[h]
\centering
\caption{Reduções ao comparar-se a potência média durante execução.}
\label{tab:avgpower}
\scalebox{0.6}{
\begin{tabular}{l c c c c c c c c c l}
App & \multicolumn{5}{c}{Redução Mínima} & \multicolumn{5}{c}{Reduçã Máxima}

\\\cmidrule(lr){2-6}\cmidrule(lr){7-11}

& Classe & NClusters & IPC(W) & ASYNC(W) & Redução(\%) & Classe & NClusters & IPC(W) & ASYNC(W) & Redução(\%)\\\midrule

FAST & Small & 16 & 4.52 & 5.14 & -13.72 & Small & 1 & 4.27 & 4.11 & 3.75 \\
FN & Large & 16 & 4.79 & 10.25 & -113.99 & Huge & 1 & 4.28 & 4.76 & -11.21 \\
GF & Huge & 16 & 4.84 & 5.91 & -22.11 & Small & 1 & 4.27 & 4.17 & 2.34 \\
IS & Large & 16 & 4.48 & 5.99 & -33.71 & Large & 1 & 4.28 & 4.41 & -3.04 \\
KM & Huge & 16 & 4.82 & 11.21 & -132.57 & Small & 1 & 4.25 & 4.71 & -10.82 \\
LU & Huge & 16 & 4.42 & 6.05 & -36.88 & Small & 1 & 4.23 & 4.09 & 3.31 \\

\bottomrule
\end{tabular}}
\end{table}

Mais importante que a potência média é o gasto energético total da aplicação. Apesar da biblioteca \ASYNC ser mais custosa em questão de potência, como ela otimiza consideravelmente o tempo de execução das aplicações, o gasto energético acaba por ser menor na grande maioria delas. A Tabela \ref{tab:energy} exibe as reduções dessa variável, as quais variaram entre -30.31 \% e 93.64 \% e a Figura \ref{fig:energy} mostra os resultados de todas as variações. Igualmente aos tempos de comunicação, os gráficos dessa métrica mostram uma tendência de parábola, a qual é regida pelo número de \clusters de determinada execução.

\begin{table}[h]
\centering
\caption{Reduções ao comparar-se o gasto energético total.}
\label{tab:energy}
\scalebox{0.6}{
\begin{tabular}{l c c c c c c c c c l}
App & \multicolumn{5}{c}{Redução Mínima} & \multicolumn{5}{c}{Reduçã Máxima}

\\\cmidrule(lr){2-6}\cmidrule(lr){7-11}

& Classe & NClusters & IPC(J) & ASYNC(J) & Redução(\%) & Classe & NClusters & IPC(J) & ASYNC(J) & Redução(\%)\\\midrule

FAST & Tiny & 16 & 38.79 & 43.92 & -13.23 & Huge & 1 & 3759.55 & 456.35 & 87.86 \\
FN & Tiny & 16 & 666.97 & 129.65 & 80.56 & Standard & 1 & 36549.92 & 2325.1 & 93.64 \\
GF & Tiny & 16 & 38.4 & 44.64 & -16.25 & Huge & 1 & 20504.65 & 1783.83 & 91.3 \\
IS & Tiny & 16 & 52.2 & 68.02 & -30.31 & Large & 1 & 751.9 & 395.02 & 47.46 \\
KM & Tiny & 16 & 47.55 & 46.21 & 2.82 & Standard & 1 & 6131.17 & 460.56 & 92.49 \\
LU & Tiny & 16 & 64.68 & 44.14 & 31.76 & Huge & 8 & 1535.77 & 103.8 & 93.24 \\

\bottomrule
\end{tabular}}
\end{table}

É possível observar que o aumento dessa métrica na versão \ASYNC acontece em contextos mais sensíveis. A Tabela \ref{tab:energy} mostra que todas as reduções mínimas aconteceram com a classe \textit{Tiny} e 16 \clusters em execução, o que é esperado, pois é nessa variação em que, segundo a Figura \ref{fig:slavetime}, sempre ocorre o menor tempo de execução. Aliado a isso, é possível ver nos gráficos dessa variável que os \kernels \FAST e \GF só obtiveram reduções negativas onde, novamente na Figura \ref{fig:slavetime}, a escala de tempo é baixíssima. Nesse contexto, como a escala do gasto energético dessas duas aplicações, se comparada às demais, também é baixa, o custo de inicialização do ambiente \ASYNC pesa bastante no resultado final. Assim, considera-se que o pequeno aumento dessa métrica nestes 2 \kernels não é algo negativo, devido a sensibilidade do contexto em que ocorre. Quanto a aplicação \IS, não é possível fazer essa afirmação pois o aumento ocorre em escalas maiores também.

\begin{figure}[h]
  \centering
  \caption{Potência média durante a execução de cada aplicação.}
  \label{fig:avgpower}
  \includegraphics[width=.9\linewidth, keepaspectratio]{avg_power.pdf}
\end{figure}

\clearpage

\begin{figure}[h]
  \centering
  \caption{Gasto energético de cada aplicação.}
  \label{fig:energy}
  \includegraphics[width=.9\linewidth, keepaspectratio]{energy.pdf}
\end{figure}

\chapter{Conclusão}
\label{ch:conclusao}

Neste trabalho, foi proposta uma nova versão do \capb com o uso da \API \ASYNC, além de uma detalhada comparação dos novos resultados obtidos em relação à implementação original que utilizava a \API \IPC no processador \mppa. A solução proposta passa por medir diferentes variáveis durante a execução das aplicações do \capb, a fim de compará-las, assim como comparar os resultados nos diferentes cenários que o \capb abrange.  Os resultados mostraram que a \API \ASYNC se sobressai em comparação com a \IPC na maioria dos cenários, ao levar em conta todas as métricas consideradas. Também foi possível observar comportamentos característicos de cada biblioteca, por exemplo, o peso maior que a \ASYNC exerce sobre a potência média ou a tendência das medições em gasto energético e tempos de comunicação formarem uma parábola em ambas as bibliotecas de comunicação, mostrando que o aumento no número de \clusters só influencia positivamente essas variáveis até certo ponto.

De maneira geral, este trabalho mostra que diretivas assíncronas são, na maioria das vezes, a melhor escolha para projetos de execução paralela. Neste caminho e, associado a um processador de arquitetura voltada ao \textit{Green Computing}, os resultados mostram também que, caso feita de maneira correta, \APIs de comunicação assíncrona em processadores de arquitetura similar podem reduzir ainda o gasto energético de determinada aplicação, bastando somente uma implementação inteligente desta.

Como trabalhos futuros, pretende-se comparar os resultados das versão \ASYNC com outros processadores \manycore e \multicore do estado da arte, a fim de avaliar se o \mppa consegue competir com estes. Além disso, pretende-se analisar detalhadamente as aplicações \capb que não obtiveram o resultado esperado nas variáveis de dados enviados e recebidos, a fim de reexaminar a possibilidade de \textit{bugs} e corrigí-los, para que nestes trabalhos possam ser apresentados resultados que batam com o que foi esperado. Por fim, pretende-se utilizar os resultados desse trabalho para uma publicação em alguma revista associada a área de computação paralela e distribuída.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
